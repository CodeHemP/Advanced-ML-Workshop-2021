{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":4,"language_info":{"name":"python","version":"3.9.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3.9.7 64-bit"},"interpreter":{"hash":"89c0967dac696469fd86f9fcc133e5067ba16b985f5faf7240d5f5ce4969c91d"},"colab":{"name":"Day 3 - Practical (Instructor Copy).ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"WeVyhvIZuzoH"},"source":["# Day 3 - Practical ‚úç\n","## Advanced ML Workshop\n","---\n","## Titanic Dataset\n","Welcome to the third practical session of SPAI's Advanced Machine Learning Workshop. In this practical, you will experience model selection, hyperparameter tuning techiniques as well as some useful feature selection techniques. Finally, you will learn how to save your model in a `.pkl` file so that you can work on it later. The goal of this dataset is to predict the survivability of passenger in the Titanic ship."]},{"cell_type":"markdown","metadata":{"id":"pXt9s8sNuzoK"},"source":["## ‚öô *Basic Initialization*\n","Please do not make any changes to this section.   \n","This section is required for the demo to work and not running it would result in errors üö®.   \n","However, if you would like to understand the code, feel free to do so üòä"]},{"cell_type":"code","metadata":{"id":"2FkynEuluzoK","executionInfo":{"status":"ok","timestamp":1632721278752,"user_tz":-480,"elapsed":1231,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}}},"source":["# Importing necessary libraries\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","import warnings\n","warnings.filterwarnings('ignore') # Filter out warnings"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"4xXSjyxvuzoM","executionInfo":{"status":"ok","timestamp":1632721279050,"user_tz":-480,"elapsed":303,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}}},"source":["titanic = pd.read_csv('https://raw.githubusercontent.com/SPAI-Team/Advanced-ML-Workshop-2021/main/Datasets/titanic_cleaned.csv', index_col=0)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Fb70hnwuzoM","executionInfo":{"status":"ok","timestamp":1632721279050,"user_tz":-480,"elapsed":3,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}}},"source":["X, y = titanic.drop(columns=['survived']), titanic['survived']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-BomSvqauzoM"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"MVIy7NGjuzoM"},"source":["## Exercise 1Ô∏è‚É£\n","In this exercise, we will be attempting to select the best model for this dataset."]},{"cell_type":"markdown","metadata":{"id":"BAs71Xf4uzoN"},"source":["> Tip üí°: Try looping through all the models! Feel free to refer to the tutorials."]},{"cell_type":"markdown","metadata":{"id":"AmwUsNSVuzoN"},"source":["#### Task\n","1. Define a `models` dictionary that stores the respective name of the model as the key, the instance of the actual model as the value\n","    - Example, `Logistic Regression` key should be filled with `LogisticRegression()` \n","    - Feel free to refer to Demonstration 1Ô∏è‚É£"]},{"cell_type":"code","metadata":{"id":"OwqJrX4QuzoN","executionInfo":{"status":"ok","timestamp":1632721358363,"user_tz":-480,"elapsed":304,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}}},"source":["# Test the following models. Evaluate which models perform the best üíØ!\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","# ensemble models are usually tested too. However, it would take far too long!\n","# from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor\n","\n","### Write your code here ###\n","# Declare a Dictionary of models with their name\n","models = {\n","    'Logistic Regression': LogisticRegression(),\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'K Neighbours': KNeighborsClassifier(),\n","    'SVC': SVC()\n","}\n","### End ###"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t92eXNJ_uzoO"},"source":["#### Task\n","1. Import `cross_validate` from `sklearn.model_selection`\n","2. Inside the for loop, apply cross validation with the `cross_validate` function you just imported and save the result in the variable `results`. In the `cross_validate` function, parse the following:\n","    - pass the model, `models[model]`\n","    - `X_train` and `y_train`\n","    - `cv=5`, `scoring=scoring_metrics`, `return_train_score=True`\n","    - Set `n_jobs` to `-1` for faster training speeds\n","3. Store all the necessary result into their necessary keys in the `scores` dictionary\n","    - The pattern is as follows, `scores[`*key*`].append(np.mean(results[`*key with underscore*`]))`\n","    - Feel free to refer to Demonstration 1Ô∏è‚É£"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YI7yIXCly8lK","executionInfo":{"status":"ok","timestamp":1632721688831,"user_tz":-480,"elapsed":305,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}},"outputId":"b050d703-8a6a-4892-c379-ec9159bd4c64"},"source":["results"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'fit_time': array([0.02140141, 0.03160548, 0.01785731, 0.01607227, 0.01774311]),\n"," 'score_time': array([0.00440311, 0.00373721, 0.00364184, 0.00368953, 0.00210428]),\n"," 'test_accuracy': array([0.76811594, 0.83211679, 0.7810219 , 0.77372263, 0.75182482]),\n"," 'test_f1': array([0.6       , 0.72289157, 0.58333333, 0.62650602, 0.51428571])}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"wPiyOxUfuzoO","executionInfo":{"status":"ok","timestamp":1632721706034,"user_tz":-480,"elapsed":835,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}},"outputId":"9c37e813-eea6-44f3-c690-d1bdc70b8b54"},"source":["scoring_metrics = ['accuracy', 'f1']\n","\n","scores = {\n","    'model': [],\n","    'train accuracy': [],\n","    'test accuracy': [],\n","    'train f1': [],\n","    'test f1': [],\n","    'fit_time': [],\n","}\n","\n","\n","### Write your code here ###\n","# import the cross_validate library from model_selection in sklearn library\n","from sklearn.model_selection import cross_validate\n","\n","# For loop through the models\n","for model in models.keys():\n","    # Initialize your results\n","    results = cross_validate(models[model], X_train, y_train, cv=5, scoring=scoring_metrics, return_train_score=True, n_jobs=-1)\n","\n","\n","\n","    # Append the corresponding results into scores\n","    scores['model'].append(model)\n","    scores['train accuracy'].append(np.mean(results['train_accuracy'])) # For train accuracy\n","    scores['test accuracy'].append(np.mean(results['test_accuracy'])) # For test accuracy\n","    scores['train f1'].append(np.mean(results['train_f1'])) # For train f1\n","    scores['test f1'].append(np.mean(results['test_f1'])) # For test f1\n","    scores['fit_time'].append(np.mean(results['fit_time'])) # For fit time\n","\n","### End ###\n","\n","\n","# Allows us to view scores in a nice format\n","pd.DataFrame(scores)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>train accuracy</th>\n","      <th>test accuracy</th>\n","      <th>train f1</th>\n","      <th>test f1</th>\n","      <th>fit_time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Logistic Regression</td>\n","      <td>0.790090</td>\n","      <td>0.781360</td>\n","      <td>0.625176</td>\n","      <td>0.609403</td>\n","      <td>0.022096</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Decision Tree</td>\n","      <td>0.954445</td>\n","      <td>0.731757</td>\n","      <td>0.921864</td>\n","      <td>0.532172</td>\n","      <td>0.004927</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>K Neighbours</td>\n","      <td>0.825437</td>\n","      <td>0.768201</td>\n","      <td>0.686208</td>\n","      <td>0.575232</td>\n","      <td>0.005847</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>SVC</td>\n","      <td>0.788995</td>\n","      <td>0.788628</td>\n","      <td>0.623589</td>\n","      <td>0.620149</td>\n","      <td>0.016756</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 model  train accuracy  ...   test f1  fit_time\n","0  Logistic Regression        0.790090  ...  0.609403  0.022096\n","1        Decision Tree        0.954445  ...  0.532172  0.004927\n","2         K Neighbours        0.825437  ...  0.575232  0.005847\n","3                  SVC        0.788995  ...  0.620149  0.016756\n","\n","[4 rows x 6 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"bsUFl1a5uzoP"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"U6Pmii2cuzoP"},"source":["## Exercise 2Ô∏è‚É£\n","In this exercise, you will learn how to use both `GridSearchCV` and `RandomSearchCV`"]},{"cell_type":"code","metadata":{"id":"-vm3ufpwuzoQ","executionInfo":{"status":"ok","timestamp":1632724405037,"user_tz":-480,"elapsed":299,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}}},"source":["dt = DecisionTreeClassifier()"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X-zwPOqbuzoQ"},"source":["### Grid Search Cross Validation\n","#### Task\n","1. Import `GridSearchCV` from `sklearn` under `model_selection`\n","2. Get the params from the Decision Tree Classifier\n","    - Do note that the `DecisionTreeClassified()` is already defined with the `dt` variable"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EIkqGNT9uzoQ","executionInfo":{"status":"ok","timestamp":1632724432951,"user_tz":-480,"elapsed":288,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}},"outputId":"69f15312-e4b7-4067-ff59-cca84f8bdf49"},"source":["### Write your code here ###\n","# Import GridSearchCV from sklearn under model_selection\n","from sklearn.model_selection import GridSearchCV\n","\n","# Get the parameters you can configure\n","dt.get_params()\n","\n","### End ###"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ccp_alpha': 0.0,\n"," 'class_weight': None,\n"," 'criterion': 'gini',\n"," 'max_depth': None,\n"," 'max_features': None,\n"," 'max_leaf_nodes': None,\n"," 'min_impurity_decrease': 0.0,\n"," 'min_impurity_split': None,\n"," 'min_samples_leaf': 1,\n"," 'min_samples_split': 2,\n"," 'min_weight_fraction_leaf': 0.0,\n"," 'presort': 'deprecated',\n"," 'random_state': None,\n"," 'splitter': 'best'}"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"tEUQtmXCuzoR"},"source":["#### Task\n","1. Set each key the array of values to experiment with. Set the following keys with the following array of values:\n","    - `min_samples_leaf` with values ranging from 2 to 6\n","    - `max_depth` with values ranging from 2 to 6\n","    - `min_samples_split` with values ranging from 1 to 5\n","    - `max_features` with values ranging from 5 to 8\n","2. Peform grid search with the `params` dictionary with the decision tree model. \n","    - Set `n_jobs` to `-1` for faster training speeds\n","    - After which, fit it with `X_train` and `y_train`\n","    - Save the grid search instance to `result` variable\n","3. Print the best score and best parameters"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vU9jogoBuzoR","executionInfo":{"status":"ok","timestamp":1632724558115,"user_tz":-480,"elapsed":4541,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}},"outputId":"6e3d1c5a-d613-47bb-b20f-01ae6652a6a8"},"source":["'''\n","Hint:\n","Range creates an iterable from the start point of a until b-1\n","range(a,b) = [a, a+1, a+2, ..., b-2, b-1]\n","'''\n","### Write your code here ###\n","# Parameters to test \n","params = {\n","    'min_samples_leaf': range(2,6),\n","    'max_depth': range(2, 6),\n","    'min_samples_split': range(1,5),\n","    'max_features': range(5, 8)\n","}\n","\n","# Runs Grid Search\n","result = GridSearchCV(dt, params, cv=5, n_jobs=-1).fit(X_train, y_train)\n","\n","# Returns Scores and parameters respectively\n","print('Best Score is:', result.best_score_)\n","print('Best Parameters:\\n', result.best_params_)\n","\n","### End ###"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Score is: 0.7974505448005924\n","Best Parameters:\n"," {'max_depth': 5, 'max_features': 5, 'min_samples_leaf': 5, 'min_samples_split': 2}\n"]}]},{"cell_type":"markdown","metadata":{"id":"964_9bqDuzoS"},"source":["### Random Search Cross Validation"]},{"cell_type":"markdown","metadata":{"id":"cLBIfnO_uzoS"},"source":["#### Task\n","1. Import `RandomSearchCV` from `sklearn` under `model_selection`"]},{"cell_type":"code","metadata":{"id":"m3d5GdnbuzoS","executionInfo":{"status":"ok","timestamp":1632724578757,"user_tz":-480,"elapsed":293,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}}},"source":["### Write your code here ###\n","# Import GridSearchCV from sklearn under model_selection\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","### End ###"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uAAbQt4buzoS"},"source":["#### Task\n","1. Peform grid search with the `params` dictionary with the decision tree model. \n","    - Set `n_jobs` to `-1` for faster training speeds\n","    - After which, fit it with `X_train` and `y_train`\n","    - Save the grid search instance to `result` variable"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FBNC0aT8uzoT","executionInfo":{"status":"ok","timestamp":1632724621788,"user_tz":-480,"elapsed":284,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}},"outputId":"788477dd-2896-4e37-f148-9c01d5e77ca1"},"source":["### Write your code here ###\n","# Runs Grid Search\n","result = RandomizedSearchCV(dt, params, cv=5, n_jobs=-1).fit(X_train, y_train)\n","\n","### End ###\n","\n","# Returns Scores and parameters respectively\n","print('Best Score is:', result.best_score_)\n","print('Best Parameters:\\n', result.best_params_)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Score is: 0.7814027292922882\n","Best Parameters:\n"," {'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 6, 'max_depth': 5}\n"]}]},{"cell_type":"markdown","metadata":{"id":"ym5cCDkguzoT"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"o8X11hYOuzoT"},"source":["## Exercise 3Ô∏è‚É£\n","In this exercise, you will learn how to carry out feature selection."]},{"cell_type":"code","metadata":{"id":"NGg4tuFquzoU","executionInfo":{"status":"ok","timestamp":1632727190615,"user_tz":-480,"elapsed":286,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}}},"source":["dt = DecisionTreeClassifier()"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TkAwAvWBuzoU"},"source":["### Feature Importance"]},{"cell_type":"markdown","metadata":{"id":"guZo7LEuuzoU"},"source":["#### Task\n","1. Train a Decision Tree Classifier model with `X_train` and `y_train`\n","2. Display Feature Importance\n","    - Feel Free to Refer to Demonstration 3Ô∏è‚É£"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"MVcuCGynuzoU","executionInfo":{"status":"ok","timestamp":1632727215885,"user_tz":-480,"elapsed":498,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}},"outputId":"9802cd19-84b0-4071-9004-b156d9cb6e4b"},"source":["### Write your code here ###\n","# Train Decision Tree Model\n","model = dt.fit(X_train, y_train)\n","\n","# Display Feature Importance\n","pd.DataFrame({\n","    'columns': X_train.columns,\n","    'feature importance': model.feature_importances_ # Call feature importance method here\n","}).sort_values('feature importance', ascending=False)\n","\n","### End ###"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>columns</th>\n","      <th>feature importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>age</td>\n","      <td>0.306653</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fare</td>\n","      <td>0.289731</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>sex_male</td>\n","      <td>0.269497</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>pclass</td>\n","      <td>0.067540</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sibsp</td>\n","      <td>0.032437</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>embarked_S</td>\n","      <td>0.026557</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>embarked_Q</td>\n","      <td>0.007585</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>parch</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      columns  feature importance\n","1         age            0.306653\n","4        fare            0.289731\n","5    sex_male            0.269497\n","0      pclass            0.067540\n","2       sibsp            0.032437\n","7  embarked_S            0.026557\n","6  embarked_Q            0.007585\n","3       parch            0.000000"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"H6kjEaTbuzoV"},"source":["### Coeffecient"]},{"cell_type":"markdown","metadata":{"id":"u4sJhQGNuzoV"},"source":["#### Task\n","1. Train a Logistic Regression model with `X_train` and `y_train`\n","2. Display the coeffecient\n","    - Hint: coeffecient is a 2D array"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"9jviShyzuzoV","executionInfo":{"status":"ok","timestamp":1632727255370,"user_tz":-480,"elapsed":518,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}},"outputId":"3b8d5a70-4e4d-4b87-f7c9-eab2721081a7"},"source":["### Write your code here ###\n","# Train Logistic Regression Model\n","model = LogisticRegression().fit(X_train, y_train)\n","\n","# Display Coeffecient\n","pd.DataFrame({\n","    'columns': X_train.columns,\n","    'coef': model.coef_[0] # Call coef method here\n","}).sort_values('coef', ascending=False)\n","\n","### End ###"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>columns</th>\n","      <th>coef</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>fare</td>\n","      <td>1.266971</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>parch</td>\n","      <td>0.000281</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>age</td>\n","      <td>-0.131962</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sibsp</td>\n","      <td>-0.384548</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>pclass</td>\n","      <td>-0.432765</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>embarked_S</td>\n","      <td>-0.471603</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>embarked_Q</td>\n","      <td>-0.574393</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>sex_male</td>\n","      <td>-2.379805</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      columns      coef\n","4        fare  1.266971\n","3       parch  0.000281\n","1         age -0.131962\n","2       sibsp -0.384548\n","0      pclass -0.432765\n","7  embarked_S -0.471603\n","6  embarked_Q -0.574393\n","5    sex_male -2.379805"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"2Zn_Kvv8uzoW"},"source":["### RFECV"]},{"cell_type":"markdown","metadata":{"id":"rbFGf1AGuzoW"},"source":["#### Task\n","1. Import `RFECV` from scikit-learn in `feature_selection`\n","2. Initialize RFECV to result and do the following:\n","    - Parse the Decision Tree Classifier Model which has been initialized with variable `dt`\n","    - Set `scoring='accuracy'` and set `n_jobs=-1` for faster fit time\n","    - Apply `.fit()` method parsing `X_train` and `y_train`\n","3. Get the ranking of each variable\n","    - Feel Free to Refer to Demonstration 4Ô∏è‚É£"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"pIpt_FStuzoW","executionInfo":{"status":"ok","timestamp":1632727328780,"user_tz":-480,"elapsed":1235,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}},"outputId":"862f3272-6b72-4f21-931b-046ed7162033"},"source":["### Write your code here ###\n","# Import RFECV from sklearn under feature_selection\n","from sklearn.feature_selection import RFECV\n","\n","# Performs RFECV\n","result = RFECV(dt, scoring='accuracy', n_jobs=-1).fit(X_train, y_train)\n","\n","# Display Ranking of features\n","pd.DataFrame({\n","    'columns': X_train.columns,\n","    'ranking': result.ranking_ # Call ranking method here\n","}).sort_values('ranking')\n","\n","### End ###"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>columns</th>\n","      <th>ranking</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>pclass</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>age</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sibsp</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>parch</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fare</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>sex_male</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>embarked_Q</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>embarked_S</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      columns  ranking\n","0      pclass        1\n","1         age        1\n","2       sibsp        1\n","3       parch        1\n","4        fare        1\n","5    sex_male        1\n","6  embarked_Q        1\n","7  embarked_S        1"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"CsBjxv_WuzoW"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"N43dNO77uzoW"},"source":["## Exercise 4Ô∏è‚É£\n","In this exercise, we will be saving and loading models."]},{"cell_type":"markdown","metadata":{"id":"_T2JAsheuzoX"},"source":["#### Task\n","1. Import joblib\n","2. Train a Decision Tree Classifier model\n","3. Save the model using `joblib`\n","    - Use the `dump` method in the joblib library\n","    - Parse the trained model and a file name of your choosing\n","    - Make sure that the file name ends with `.pkl`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hRs4uRTbuzoX","executionInfo":{"status":"ok","timestamp":1632728571417,"user_tz":-480,"elapsed":306,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}},"outputId":"9d5c9c9e-cddd-412a-ecbb-c416cbc4df1e"},"source":["### Write your code here ###\n","# Import Joblib library\n","import joblib\n","\n","# Train Decision Tree Classifier\n","model = DecisionTreeClassifier().fit(X_train, y_train)\n","\n","# Save the model\n","joblib.dump(model, 'day 3.pkl')\n","\n","### End ###"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['day 3.pkl']"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"7lYxw9iquzoX"},"source":["#### Task\n","1. Load the model from the `.pkl` file with the file name used in the previous cell.\n","    - Be sure to load the model into the variable `model`\n","2. Generate prediction from the model\n","    - run `.predict` method using `X_test`\n","3. Use your testing data to test the accuracy of the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqtbsAAkuzoX","executionInfo":{"status":"ok","timestamp":1632728612680,"user_tz":-480,"elapsed":281,"user":{"displayName":"Zheng Kai Ong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTTk_bnwGBljc3Anw_Hw6miLFk8lIi3XqJBZI8RBU=s64","userId":"17151805907447128704"}},"outputId":"37c703ed-9e26-4f5c-e421-2e7c8f3f5e23"},"source":["### Write your code here ###\n","# Load the model from the saved .pkl file\n","model = joblib.load('day 3.pkl')\n","\n","# Generate predictions\n","y_pred = model.predict(X_test)\n","\n","# Test accuracy of the model\n","accuracy_score(y_test, y_pred)\n","\n","### End ###"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7848837209302325"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"JpjunJxFXbNv"},"source":["# Conclusion\n","Congratulations! You have completed Practical Notebook for Day 3 of SPAI Advanced Machine Learning Workshop.  If you have any doubts or require any clarification feel free to approach us through our [Instagram](https://www.instagram.com/spai.sp/) or [Discord Server](https://discord.gg/zPYJMGfQFa)*(remember to verified yourself)*.\n","\n","---\n","> ### Feel Free to Join the Subsequent **SPAI Machine Learning Competition** to earn **valuable Prizeüí∞ and ExperienceüèÜ** if you have not done so!ü•≥ü•≥\n","[ML Comp Sign Up Link](https://docs.google.com/forms/d/e/1FAIpQLSchLDXDAY0LqM6fuRDyQwdRNbVT4FYrgDtqthEIfYpFvpWMAg/viewform) *(If it has not been closed)*"]}]}